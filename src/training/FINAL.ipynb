{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taupork/DSA/blob/main/FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "simAT-bxyzPa",
        "outputId": "2d0acd11-bc36-4b12-c10d-00d8904aa20c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "CSV_PATH = \"/content/drive/MyDrive/DSA_Comp/dataset.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW5hAmwFxArL"
      },
      "source": [
        "### Training SSL Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjEc1DPTw5xm",
        "outputId": "40d056e4-afee-4e41-e214-92c864ea8696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import optuna\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import pillow_heif\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Register HEIF opener (if using HEIC/HEIF images)\n",
        "pillow_heif.register_heif_opener()\n",
        "\n",
        "# ---------------------------\n",
        "# Configuration / Reproducibility\n",
        "# ---------------------------\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Utilities\n",
        "# ---------------------------\n",
        "def make_run_dir(base=\"models\", prefix=\"run\"):\n",
        "    ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    run_dir = os.path.join(base, f\"{prefix}_{ts}\")\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "    return run_dir\n",
        "\n",
        "def safe_save_json(df, path):\n",
        "    try:\n",
        "        df.to_json(path, orient=\"records\", lines=True)\n",
        "    except Exception:\n",
        "        df.to_csv(path.replace(\".json\", \".csv\"), index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset Classes\n",
        "# ---------------------------\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "\n",
        "class HbImageDataset(Dataset):\n",
        "    \"\"\"Labeled dataset for supervised + SSL training\"\"\"\n",
        "    def __init__(self, df, transform=None, path_col=\"Filename\", target_col=\"Hb\", n_views=2):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "        self.path_col = path_col\n",
        "        self.target_col = target_col\n",
        "        self.n_views = n_views\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = Image.open(row[self.path_col]).convert(\"RGB\")\n",
        "        if self.n_views == 1:\n",
        "            return self.transform(img).unsqueeze(0), torch.tensor(row[self.target_col], dtype=torch.float32)\n",
        "        else:\n",
        "            views = [self.transform(img) for _ in range(self.n_views)]\n",
        "            return torch.stack(views), torch.tensor(row[self.target_col], dtype=torch.float32)\n",
        "\n",
        "class UnlabelledImageDataset(Dataset):\n",
        "    \"\"\"Unlabeled dataset for SSL pretraining, supports subfolders\"\"\"\n",
        "    def __init__(self, root_dir, transform=None, n_views=2):\n",
        "        self.image_paths = []\n",
        "        for dirpath, _, filenames in os.walk(root_dir):\n",
        "            for fname in filenames:\n",
        "                if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".heic\", \".heif\")):\n",
        "                    self.image_paths.append(os.path.join(dirpath, fname))\n",
        "        self.transform = transform\n",
        "        self.n_views = n_views\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        if self.n_views == 1:\n",
        "            return self.transform(img).unsqueeze(0)\n",
        "        else:\n",
        "            views = [self.transform(img) for _ in range(self.n_views)]\n",
        "            return torch.stack(views)\n",
        "\n",
        "class CombinedImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Combines a labeled DataFrame dataset and an unlabelled image directory for SSL.\n",
        "    Supports multi-view transformations for contrastive learning.\n",
        "    Returns (views, target, is_labeled).\n",
        "    Logs the number of labeled and unlabeled images loaded.\n",
        "    \"\"\"\n",
        "    def __init__(self, labelled_df=None, unlabelled_dir=None, transform=None, path_col=\"Filename\", target_col=\"Hb\", n_views=2):\n",
        "        self.labelled_dataset = None\n",
        "        self.unlabelled_dataset = None\n",
        "\n",
        "        if labelled_df is not None:\n",
        "            self.labelled_dataset = HbImageDataset(\n",
        "                labelled_df, transform=transform, path_col=path_col, target_col=target_col, n_views=n_views\n",
        "            )\n",
        "            print(f\"[INFO] Loaded {len(self.labelled_dataset)} labeled images for SSL pretraining.\")\n",
        "\n",
        "        if unlabelled_dir is not None:\n",
        "            self.unlabelled_dataset = UnlabelledImageDataset(\n",
        "                unlabelled_dir, transform=transform, n_views=n_views\n",
        "            )\n",
        "            print(f\"[INFO] Loaded {len(self.unlabelled_dataset)} unlabeled images for SSL pretraining.\")\n",
        "\n",
        "        # Compute total length\n",
        "        self.labelled_len = len(self.labelled_dataset) if self.labelled_dataset else 0\n",
        "        self.unlabelled_len = len(self.unlabelled_dataset) if self.unlabelled_dataset else 0\n",
        "        self.total_len = self.labelled_len + self.unlabelled_len\n",
        "        print(f\"[INFO] Total images in combined dataset: {self.total_len}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labelled_dataset and idx < self.labelled_len:\n",
        "            views, target = self.labelled_dataset[idx]\n",
        "            return views, target, True  # True indicates labeled\n",
        "        else:\n",
        "            unlabelled_idx = idx - self.labelled_len\n",
        "            views = self.unlabelled_dataset[unlabelled_idx]\n",
        "            dummy_target = torch.tensor(-1.0)  # Dummy target for unlabeled\n",
        "            return views, dummy_target, False  # False indicates unlabelled\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Transforms\n",
        "# ---------------------------\n",
        "ssl_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    # transforms.ColorJitter(0.4,0.4,0.4,0.1), => May be too strong for hb predictions\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "# ---------------------------\n",
        "# ResNet Backbone + Projection Head\n",
        "# ---------------------------\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(self, input_dim=512, hidden_dim=256, output_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def get_ssl_backbone(pretrained=True):\n",
        "    resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "    backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "    return backbone.to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# NT-Xent Loss\n",
        "# ---------------------------\n",
        "def nt_xent_loss(z_i, z_j, temperature=0.5):\n",
        "    z_i = nn.functional.normalize(z_i, dim=1)\n",
        "    z_j = nn.functional.normalize(z_j, dim=1)\n",
        "    batch_size = z_i.size(0)\n",
        "    representations = torch.cat([z_i, z_j], dim=0)\n",
        "    similarity_matrix = torch.matmul(representations, representations.T) / temperature\n",
        "    mask = torch.eye(2*batch_size, device=z_i.device).bool()\n",
        "    similarity_matrix = similarity_matrix.masked_fill(mask, -1e9)\n",
        "    labels = torch.arange(batch_size, device=z_i.device)\n",
        "    labels = torch.cat([labels + batch_size, labels], dim=0)\n",
        "    return nn.CrossEntropyLoss()(similarity_matrix, labels)\n",
        "\n",
        "# ---------------------------\n",
        "# SSL Pretraining (supports unlabeled or labeled)\n",
        "# ---------------------------\n",
        "def pretrain_ssl(labelled_df=None,\n",
        "                          unlabelled_dir=None,\n",
        "                          transform=ssl_transform,\n",
        "                          epochs=20,\n",
        "                          batch_size=8,\n",
        "                          lr=1e-3,\n",
        "                          num_workers=2,\n",
        "                          run_dir=None):\n",
        "\n",
        "    dataset = CombinedImageDataset(labelled_df=labelled_df,\n",
        "                                   unlabelled_dir=unlabelled_dir,\n",
        "                                   transform=transform,\n",
        "                                   n_views=2)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    backbone = get_ssl_backbone(pretrained=True)\n",
        "    proj_head = ProjectionHead().to(device)\n",
        "    optimizer = torch.optim.Adam(list(backbone.parameters()) + list(proj_head.parameters()), lr=lr)\n",
        "\n",
        "    backbone.train()\n",
        "    proj_head.train()\n",
        "    ssl_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for batch in loader:\n",
        "            views, target, is_labeled = batch\n",
        "            v1, v2 = views[:,0].to(device), views[:,1].to(device)\n",
        "\n",
        "            feats1 = backbone(v1).view(v1.size(0), -1)\n",
        "            feats2 = backbone(v2).view(v2.size(0), -1)\n",
        "            z1 = proj_head(feats1)\n",
        "            z2 = proj_head(feats2)\n",
        "            loss = nt_xent_loss(z1, z2)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(loader) if len(loader) > 0 else float(\"nan\")\n",
        "        ssl_losses.append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - SSL Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    if run_dir:\n",
        "        torch.save(backbone.state_dict(), os.path.join(run_dir, \"ssl_backbone_state_dict.pth\"))\n",
        "        torch.save(proj_head.state_dict(), os.path.join(run_dir, \"ssl_projection_head_state_dict.pth\"))\n",
        "        pd.DataFrame({\"ssl_loss\": ssl_losses}).to_csv(os.path.join(run_dir, \"ssl_loss_history.csv\"), index=False)\n",
        "\n",
        "    return backbone, proj_head, ssl_losses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf7bc6rAx13L"
      },
      "source": [
        "#### Train SSL Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAzqUvEpxzZJ",
        "outputId": "de75a3d7-2df2-4cd4-99ca-a4b649b801ed"
      },
      "outputs": [],
      "source": [
        "run_dir = make_run_dir(base=\"models\", prefix=\"ssl_combined\")\n",
        "\n",
        "backbone, proj_head, ssl_losses = pretrain_ssl(\n",
        "    labelled_df=df,       # your labelled DataFrame\n",
        "    unlabelled_dir=\"/content/drive/MyDrive/DSA_Comp/Lip Images\",  # path to unlabelled images\n",
        "    transform=ssl_transform,\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    lr=1e-3,\n",
        "    num_workers=4,\n",
        "    run_dir=run_dir\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training + Validating Regressor Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXQdpkk8zbWg"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Feature Extraction\n",
        "# ---------------------------\n",
        "def extract_embeddings(df, backbone, transform, path_col=\"Filename\", target_col=\"Hb\", batch_size=8, num_workers=2):\n",
        "    dataset = HbImageDataset(df, transform, n_views=1, path_col=path_col, target_col=target_col)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    backbone.eval()\n",
        "\n",
        "    feats, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for views, hb in loader:\n",
        "            img = views[:,0].to(device)\n",
        "            emb = backbone(img).view(img.size(0), -1)\n",
        "            feats.append(emb.cpu().numpy())\n",
        "            targets.extend(hb.cpu().numpy())\n",
        "    if len(feats) == 0:\n",
        "        return np.zeros((0,512)), np.array([])\n",
        "    return np.vstack(feats), np.array(targets)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Combine Metadata\n",
        "# ---------------------------\n",
        "def combine_metadata(features, df, cols_to_include=None):\n",
        "    df_reset = df.reset_index(drop=True)\n",
        "    if cols_to_include is None:\n",
        "        cols_to_include = [c for c in [\"IndividualID\",\"ImageNo\"] if c in df_reset.columns]\n",
        "    if cols_to_include:\n",
        "        metadata = df_reset[cols_to_include].values\n",
        "        if len(metadata) != len(features):\n",
        "            print(f\"Warning: metadata rows ({len(metadata)}) != feature rows ({len(features)}) -> ignoring metadata\")\n",
        "            return features\n",
        "        try:\n",
        "            metadata = metadata.astype(np.float32)\n",
        "        except Exception:\n",
        "            print(\"Metadata not numeric; skipping metadata concatenation.\")\n",
        "            return features\n",
        "        return np.hstack([features, metadata])\n",
        "    return features\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def run_ssl_pipeline_kfold_with_r2(labeled_df,\n",
        "                                   unlabelled_dir=None,\n",
        "                                   ssl_epochs=20,\n",
        "                                   ssl_batch=8,\n",
        "                                   fine_tune_backbone=True,\n",
        "                                   fine_tune_epochs=10,\n",
        "                                   use_metadata=False,\n",
        "                                   optuna_trials=20,\n",
        "                                   run_base_dir=\"models\",\n",
        "                                   load_run_dir=None,\n",
        "                                   n_splits=5):\n",
        "\n",
        "    run_dir = load_run_dir if load_run_dir else make_run_dir(run_base_dir)\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "    print(f\"Run directory: {run_dir}\")\n",
        "\n",
        "    # -------------------\n",
        "    # Load or pretrain SSL backbone\n",
        "    # -------------------\n",
        "    backbone = get_ssl_backbone(pretrained=False)\n",
        "    proj_head = ProjectionHead().to(device)\n",
        "\n",
        "    if load_run_dir and os.path.exists(os.path.join(run_dir, \"ssl_backbone_state_dict.pth\")):\n",
        "        backbone.load_state_dict(torch.load(os.path.join(run_dir, \"ssl_backbone_state_dict.pth\"), map_location=device))\n",
        "        proj_head.load_state_dict(torch.load(os.path.join(run_dir, \"ssl_projection_head_state_dict.pth\"), map_location=device))\n",
        "        backbone.to(device).eval()\n",
        "        proj_head.to(device).eval()\n",
        "        print(\"Loaded pretrained backbone and projection head from saved run.\")\n",
        "    else:\n",
        "        print(\"=== SSL Pretraining ===\")\n",
        "        if unlabelled_dir:\n",
        "            backbone, proj_head, ssl_losses = pretrain_ssl(unlabelled_dir, ssl_transform,\n",
        "                                                           epochs=ssl_epochs, batch_size=ssl_batch,\n",
        "                                                           run_dir=run_dir, unlabelled=True)\n",
        "        else:\n",
        "            backbone, proj_head, ssl_losses = pretrain_ssl(labeled_df, ssl_transform,\n",
        "                                                           epochs=ssl_epochs, batch_size=ssl_batch,\n",
        "                                                           run_dir=run_dir, unlabelled=False)\n",
        "\n",
        "    # -------------------\n",
        "    # K-Fold CV\n",
        "    # -------------------\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
        "    fold_metrics = []\n",
        "\n",
        "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(labeled_df)):\n",
        "        print(f\"\\n--- K-Fold {fold_idx+1}/{n_splits} ---\")\n",
        "        train_df, test_df = labeled_df.iloc[train_idx], labeled_df.iloc[test_idx]\n",
        "\n",
        "        # Fine-tune backbone if required\n",
        "        if fine_tune_backbone:\n",
        "            dataset = HbImageDataset(train_df, transform=ssl_transform, n_views=2)\n",
        "            loader = DataLoader(dataset, batch_size=ssl_batch, shuffle=True, num_workers=2, pin_memory=True)\n",
        "            backbone.train()\n",
        "            proj_head.train()\n",
        "            optimizer = torch.optim.Adam(list(backbone.parameters()) + list(proj_head.parameters()), lr=1e-4)\n",
        "            for epoch in range(fine_tune_epochs):\n",
        "                total_loss = 0.0\n",
        "                for views, _ in loader:\n",
        "                    v1, v2 = views[:,0].to(device), views[:,1].to(device)\n",
        "                    feats1, feats2 = backbone(v1).view(v1.size(0), -1), backbone(v2).view(v2.size(0), -1)\n",
        "                    z1, z2 = proj_head(feats1), proj_head(feats2)\n",
        "                    loss = nt_xent_loss(z1, z2)\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    total_loss += loss.item()\n",
        "                print(f\"Fold {fold_idx+1} Epoch {epoch+1} Loss: {total_loss/len(loader):.4f}\")\n",
        "\n",
        "        # Extract embeddings\n",
        "        X_train, y_train = extract_embeddings(train_df, backbone, val_transform)\n",
        "        X_test, y_test = extract_embeddings(test_df, backbone, val_transform)\n",
        "\n",
        "        # Optuna hyperparameter tuning\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                \"n_estimators\": trial.suggest_int(\"n_estimators\",50,300),\n",
        "                \"max_depth\": trial.suggest_int(\"max_depth\",2,10),\n",
        "                \"learning_rate\": trial.suggest_float(\"learning_rate\",0.01,0.3,log=True),\n",
        "                \"subsample\": trial.suggest_float(\"subsample\",0.5,1.0),\n",
        "                \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\",0.5,1.0),\n",
        "                \"random_state\": RANDOM_SEED,\n",
        "                \"verbosity\": 0,\n",
        "                \"n_jobs\": 1,\n",
        "                \"tree_method\": \"hist\"\n",
        "            }\n",
        "            kf_inner = KFold(n_splits=min(5, len(train_df)), shuffle=True, random_state=RANDOM_SEED)\n",
        "            maes = []\n",
        "            for tr_idx, val_idx in kf_inner.split(X_train):\n",
        "                model = xgb.XGBRegressor(**params)\n",
        "                model.fit(X_train[tr_idx], y_train[tr_idx])\n",
        "                y_pred = model.predict(X_train[val_idx])\n",
        "                maes.append(mean_absolute_error(y_train[val_idx], y_pred))\n",
        "            return np.mean(maes)\n",
        "\n",
        "        study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED))\n",
        "        study.optimize(objective, n_trials=optuna_trials, show_progress_bar=False)\n",
        "        best_params = study.best_params\n",
        "        print(f\"Best params fold {fold_idx+1}: {best_params}\")\n",
        "\n",
        "        # Train final model\n",
        "        final_model = xgb.XGBRegressor(**best_params, random_state=RANDOM_SEED, n_jobs=-1, tree_method=\"hist\")\n",
        "        final_model.fit(X_train, y_train)\n",
        "        y_pred = final_model.predict(X_test)\n",
        "\n",
        "        # Compute metrics including R²\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f\"[Fold {fold_idx+1}] RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "        fold_metrics.append({\"fold\": fold_idx+1, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2})\n",
        "\n",
        "    # -------------------\n",
        "    # Summary metrics\n",
        "    # -------------------\n",
        "    metrics_df = pd.DataFrame(fold_metrics)\n",
        "    metrics_df.loc[\"Mean\"] = metrics_df.mean()\n",
        "    print(\"\\n=== Fold Metrics Summary ===\")\n",
        "    print(metrics_df)\n",
        "\n",
        "    # Save metrics and models\n",
        "    metrics_df.to_csv(os.path.join(run_dir, \"kfold_metrics.csv\"), index=False)\n",
        "    torch.save(backbone.state_dict(), os.path.join(run_dir, \"ssl_backbone_state_dict.pth\"))\n",
        "    torch.save(proj_head.state_dict(), os.path.join(run_dir, \"ssl_projection_head_state_dict.pth\"))\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(metrics_df['fold'][:-1], metrics_df['RMSE'][:-1], marker='o', label='RMSE')\n",
        "    plt.plot(metrics_df['fold'][:-1], metrics_df['MAE'][:-1], marker='s', label='MAE')\n",
        "    plt.plot(metrics_df['fold'][:-1], metrics_df['R2'][:-1], marker='^', label='R²')\n",
        "    plt.axhline(metrics_df.loc[\"Mean\", 'RMSE'], color='blue', linestyle='--', alpha=0.5)\n",
        "    plt.axhline(metrics_df.loc[\"Mean\", 'MAE'], color='orange', linestyle='--', alpha=0.5)\n",
        "    plt.axhline(metrics_df.loc[\"Mean\", 'R2'], color='green', linestyle='--', alpha=0.5)\n",
        "    plt.xlabel(\"Fold\")\n",
        "    plt.ylabel(\"Metric Value\")\n",
        "    plt.title(\"K-Fold Regression Metrics (RMSE, MAE, R²)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(run_dir, \"kfold_metrics_plot.png\"))\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        \"backbone\": backbone,\n",
        "        \"proj_head\": proj_head,\n",
        "        \"metrics_df\": metrics_df,\n",
        "        \"run_dir\": run_dir\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ganAph2heYH3"
      },
      "source": [
        "### R2 Kfold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWdLnP3a7-Yp"
      },
      "source": [
        "#### K Folder Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF-OEqHKlCuL"
      },
      "source": [
        "#### Current Best (SSL + Finetuning) High R2 > 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S3NtZuf0i29k",
        "outputId": "4cc32288-9464-4a71-baa0-5dadf493076e"
      },
      "outputs": [],
      "source": [
        "loaded_results = run_ssl_pipeline_kfold_with_r2(\n",
        "    labeled_df=df,\n",
        "    load_run_dir=\"/content/drive/MyDrive/DSA_Comp/ssl_models/ssl_740\",\n",
        "    fine_tune_epochs = 25\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYPYHQUEt1-x"
      },
      "source": [
        "#### SSL MultiTask Only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jRiEht5st2cM",
        "outputId": "4ab94081-354b-4ee1-c6ce-8112ee1bedb2"
      },
      "outputs": [],
      "source": [
        "loaded_results = run_ssl_pipeline_kfold_with_r2(\n",
        "    labeled_df=df,\n",
        "    load_run_dir=\"/content/drive/MyDrive/DSA_Comp/ssl_models/ssl_multi\",\n",
        "    fine_tune_epochs = 0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BvooSC9qXUq"
      },
      "source": [
        "#### SSL Multi Task + Finetuning == Horrible R2 <0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxejCoB7qUhb",
        "outputId": "72f42ab6-ea20-4520-fbeb-ec11b64d9f1d"
      },
      "outputs": [],
      "source": [
        "loaded_results = run_ssl_pipeline_kfold_with_r2(\n",
        "    labeled_df=df,\n",
        "    load_run_dir=\"/content/drive/MyDrive/DSA_Comp/ssl_models/ssl_multi\",\n",
        "    fine_tune_epochs = 25\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOyGXR6C4LXlG4pEf6ndZab",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1H-btvdc3lU7wQ4DhZWaiurikzYqko5Ss",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "156ef0eda8504397aa5495e5dcd2ba43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "22e06509b67c4c098760a4a3dd0d4c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23830de5000342f2af13414addefa744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390db69d337644bd9a984d4b7e94ac1e",
            "max": 102469840,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_156ef0eda8504397aa5495e5dcd2ba43",
            "value": 102469840
          }
        },
        "390db69d337644bd9a984d4b7e94ac1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b3ddf6450e403bb1dbb8d6b5d8a417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce78233a233b47bdb25e9d43c38784ed",
            "placeholder": "​",
            "style": "IPY_MODEL_22e06509b67c4c098760a4a3dd0d4c09",
            "value": " 102M/102M [00:01&lt;00:00, 131MB/s]"
          }
        },
        "79da2476cb934d329ec0650f4146dca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f477111d3f0a48558e1bcc42674e6d94",
            "placeholder": "​",
            "style": "IPY_MODEL_dbe03b9b96b24f1b979af43d2beb1601",
            "value": "model.safetensors: 100%"
          }
        },
        "7ba41850fa8d4100828e5f655899321d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79da2476cb934d329ec0650f4146dca3",
              "IPY_MODEL_23830de5000342f2af13414addefa744",
              "IPY_MODEL_75b3ddf6450e403bb1dbb8d6b5d8a417"
            ],
            "layout": "IPY_MODEL_92ef309f4e16493893c5bfa19eaf4019"
          }
        },
        "92ef309f4e16493893c5bfa19eaf4019": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce78233a233b47bdb25e9d43c38784ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbe03b9b96b24f1b979af43d2beb1601": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f477111d3f0a48558e1bcc42674e6d94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
